{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a72c20",
   "metadata": {},
   "source": [
    "# web scraping Listings usings BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_real_estate_data(url,rent=None):\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    print(response.status_code)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract property listings\n",
    "        listings = soup.find_all('div', class_='lazyload-wrapper')\n",
    "        \n",
    "        \n",
    "        \n",
    "        properties = []\n",
    "        # Extract data from each listing\n",
    "        for listing in listings:\n",
    "            # Extract property details (e.g., price, location, etc.)\n",
    "            link_tag = listing.find('div', class_='results_card')\n",
    "            link = link_tag.find('a')['href']\n",
    "            \n",
    "            price = listing.find('span', class_='price').text\n",
    "            if rent:\n",
    "                _ ,price,_, _ = price.replace(\"\\xa0\",\" \").split(\" \")\n",
    "            else:\n",
    "                try:\n",
    "                    _ ,price = price.strip().replace(\"\\xa0\",\" \").strip().split(\" \")\n",
    "                    \n",
    "                except:\n",
    "                    price = \"0,\"\n",
    "                \n",
    "            title_location_div = listing.find('div', class_='card_title')\n",
    "            title=title_location_div.find(\"h2\").text.strip()\n",
    "            location=title_location_div.find(\"h5\").text.strip()\n",
    "            \n",
    "            # Extract image URL if available\n",
    "            image_url_div = listing.find('div', class_='results_card_media')\n",
    "            image_url = image_url_div.find_all('img')[2]['src'] \n",
    "\n",
    "            # desciptions\n",
    "            desc_tag = listing.find('ul',class_='results_card_details')            \n",
    "            desc = \"\"\n",
    "            \n",
    "            # Extract the text of the <li> tag and concatenate it with the existing descriptions\n",
    "            for li_tag in desc_tag.find_all( ['li','p'] ):\n",
    "                desc +=  li_tag.text + \" | \"\n",
    "                \n",
    "            response_click=requests.get(link)\n",
    "            if response_click.status_code == 200:\n",
    "                soup_click = BeautifulSoup(response_click.text,\"html.parser\")\n",
    "                sub_listings = soup_click.find(\"div\",class_=\"tower_description\")\n",
    "                description = sub_listings.find(\"p\").text.strip() if sub_listings.find(\"p\") else \"\"\n",
    "                summary = soup_click.find(\"div\",class_=\"tower_detail\").find(\"h1\").text\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                description=\"\"\n",
    "\n",
    "                \n",
    "            # get agents contact\n",
    "            \n",
    "            ag_name = listing.find('div',class_='agent_name').find('span').text\n",
    "            \n",
    "            ag_whatsapp = listing.find('div',class_='agent_contact').find('a')['href']\n",
    "            ag_call = listing.find('div',class_='agent_contact').find_all('a')[1]['href']\n",
    "            \n",
    "            #get the bed and = bath\n",
    "            \n",
    "            bed_bath_div = listing.find(\"div\",class_=\"about_tour\")\n",
    "            bed , bath , sqft = bed_bath_div.find_all(\"span\")  # this will be 3 list 0-bed 1-bath 2-hight(not using it)\n",
    "            sqft, _ = sqft.text.split(\" \")\n",
    "            number_of_beds =int(bed.text) if  bed  else 0\n",
    "            number_of_baths = int(bath.text) if  bath.text.isdigit()  else 0\n",
    "            size_in_sqft = int(sqft.replace(\",\",\"\")) if sqft else 0\n",
    "            \n",
    "            \n",
    "            \n",
    "            properties.append ({\n",
    "                'title': title,\n",
    "                'description': desc,\n",
    "                'price_in_aed': int(price.replace(\",\",\"\")), \n",
    "                'location': location,\n",
    "                'number_of_beds': number_of_beds,\n",
    "                'number_of_baths':number_of_baths ,\n",
    "                \"size_in_sqft\": size_in_sqft,\n",
    "                'sale_type': \"rent\" if rent else \"buy\",\n",
    "                'page_url':link,\n",
    "                'image_url': image_url,\n",
    "                'agent_name':ag_name,\n",
    "                'whatsapp_link':ag_whatsapp,\n",
    "                'call_agent':ag_call,\n",
    "                'long_description': description,\n",
    "                \"summary\":summary\n",
    "                \n",
    "            })\n",
    "        \n",
    "        return properties\n",
    "    else:\n",
    "        print(\"Failed to fetch the page\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c64f7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## NOW LETS GRAP SOME MORE PAGES AND STORE TO DF\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "num_pages = 20\n",
    "starter = 0\n",
    "rent_listings= []\n",
    "sale_listings= []\n",
    "st = time.time()\n",
    "for _ in range(2):\n",
    "    rent=True\n",
    "    \n",
    "    for i in range(num_pages):\n",
    "        url_rent= f\"https://www.allsoppandallsopp.com/dubai/properties/residential/lettings/page-{starter+i+1}\"\n",
    "        listings = scrape_real_estate_data(url_rent,rent)\n",
    "        rent_listings += listings\n",
    "\n",
    "        time.sleep(30)\n",
    "        print(\"rent_page : \", f\"{starter+i+1}/40\")\n",
    "\n",
    "\n",
    "    time.sleep(300)\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        url_sale= f\"https://www.allsoppandallsopp.com/dubai/properties/residential/sales/page-{starter+i+1}\"\n",
    "        listings = scrape_real_estate_data(url_sale)\n",
    "        sale_listings += listings\n",
    "\n",
    "        time.sleep(30)\n",
    "\n",
    "        print(\"sale_page : \", starter+i+1,\"/40\")\n",
    "            \n",
    "\n",
    "\n",
    "        time.sleep(300)\n",
    "        starter = starter+20\n",
    "end= time.time()\n",
    "\n",
    "print(\"rantime: {end-st}\")\n",
    "\n",
    "rent_json=rent_listings\n",
    "sale_json=sale_listings\n",
    "\n",
    "rent_df = pd.DataFrame(rent_json)\n",
    "sale_df = pd.DataFrame(sale_json)\n",
    "\n",
    "\n",
    "df_final = shuffle(pd.concat([rent_df,sale_df]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbd64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df = df_final\n",
    "columns_to_separate=[\"page_url\",\"image_url\",\"call_agent\",\"whatsapp_link\",\"agent_name\"] \n",
    "property_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "property_df = property_df[~property_df.index.isin([51, 71])]  ## contains np.nan // unusable listings\n",
    "extras= property_df[columns_to_separate]\n",
    "\n",
    "property_df.drop(columns_to_separate ,axis=1,inplace=True)\n",
    "\n",
    "property_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "extras.reset_index(inplace=True,drop=True)\n",
    "\n",
    "ids = pd.DataFrame({\"id\":list(range(1,len(extras) + 1 ))})\n",
    "                   \n",
    "extras = pd.concat([ids,extras],axis=1)\n",
    "property_df = pd.concat([ids, property_df],axis=1)\n",
    "\n",
    "property_df[\"id\"][8]==9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_please(text):\n",
    "    parts = text.split(\"Please\")  ## we have plese call and note\n",
    "    return parts[0].strip() if len(parts) > 1 else text\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to the 'description' column\n",
    "property_df['long_description'] = property_df['long_description'].apply(remove_after_please)\n",
    "                                                              \n",
    "for _ in range(10):\n",
    "    property_df.long_description = (property_df.long_description+\" in \"\n",
    "                                    +property_df.location +\" price \"\n",
    "                                    +property_df.price_in_aed.astype(str) +\" aed \"\n",
    "                                    +\" \"\n",
    "                                    +property_df.number_of_beds.astype(str)+\" bedrooms for \")\n",
    "    property_df.long_description += property_df.sale_type if all(property_df.sale_type) ==\"rent\" else \"sale\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5727515a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the results to csv\n",
    "\n",
    "property_df.to_csv(\"estate_data.csv\")\n",
    "\n",
    "EXTRAS = pd.concat([extras,property_df.description,property_df.title,property_df.location,property_df.sale_type,property_df.number_of_beds,property_df.price_in_aed],axis=1)\n",
    "EXTRAS.to_csv(\"contact_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7909f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
